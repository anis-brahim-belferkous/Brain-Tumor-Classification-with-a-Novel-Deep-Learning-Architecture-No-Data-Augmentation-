# -*- coding: utf-8 -*-
"""97model01_11at10_20.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17wLoxPv9j7LjPTo1FVMW7ANTbUTvMDRn
"""

!pip install imutils

!pip install tensorflow

!pip install keras-rectified-adam

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import os
from os import listdir
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline
import imutils
from PIL import Image, ImageEnhance


import random #!!!!

from tensorflow.keras.models import Model,load_model
from tensorflow.keras.layers import Conv2D,Input,ZeroPadding2D,BatchNormalization,Flatten,Activation,Dense,MaxPooling2D
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle #shuffling the data improves the model

data_path_training_dir="/content/drive/MyDrive/braintumor_dataset/Training"
data_path_testing_dir="/content/drive/MyDrive/braintumor_dataset/Testing"

sub_dirs= os.listdir(data_path_training_dir)

output_dictionay = {}

for i in range(len(sub_dirs)):
    output_dictionay.update({sub_dirs[i]:i})

print('The tumor classes availables are',output_dictionay,'.\n')

"""Reading data"""

train_paths = []
train_labels = []

for label in sub_dirs:
    for image in os.listdir(data_path_training_dir+'/'+label):
        train_paths.append(data_path_training_dir+label+'/'+image)
        train_labels.append(label)

train_paths, train_labels = shuffle(train_paths, train_labels)

plt.figure(figsize=(14,6))
colors = ['#4285f4', '#ea4335', '#fbbc05', '#34a853']
plt.rcParams.update({'font.size': 18})
plt.pie([len([x for x in train_labels if x=='pituitary']),
         len([x for x in train_labels if x=='notumor']),
         len([x for x in train_labels if x=='meningioma']),
         len([x for x in train_labels if x=='glioma'])],
        labels=['pituitary','notumor', 'meningioma', 'glioma'],
        colors=colors, autopct='%.1f%%', explode=(0.025,0.025,0.025,0.025),
        startangle=30);

"""
**The dataset is reasonably balanced**


"""

test_paths = []
test_labels = []

for label in os.listdir(data_path_testing_dir):
    for image in os.listdir(data_path_testing_dir+'/'+label):
        test_paths.append(data_path_testing_dir+label+'/'+image)
        test_labels.append(label)

test_paths, test_labels = shuffle(test_paths, test_labels)

plt.figure(figsize=(14,6))
colors = ['#4285f4', '#ea4335', '#fbbc05', '#34a853']
plt.rcParams.update({'font.size': 14})
plt.pie([len(train_labels), len(test_labels)],
        labels=['Train','Test'],
        colors=colors, autopct='%.1f%%', explode=(0.05,0),
        startangle=30);

from os import listdir, path, remove
import cv2

def remove_none_images(directory):
    # Iterate over each subdirectory in the main directory
    for subdirectory in listdir(directory):
        subdirectory_path = path.join(directory, subdirectory)

        # Check if it's a directory
        if path.isdir(subdirectory_path):
            print(f"Processing subdirectory: {subdirectory}")

            # Iterate over each file in the subdirectory
            for filename in listdir(subdirectory_path):
                file_path = path.join(subdirectory_path, filename)

                # Check if it's a file
                if path.isfile(file_path):
                    # Read the image
                    image = cv2.imread(file_path)

                    # Check if image is read successfully
                    if image is None:
                        print(f"Deleting none image: {filename}")
                        # Remove the file from the subdirectory
                        remove(file_path)

# Example usage:
# replace 'path_to_your_directory' with the actual path to your directory
remove_none_images(data_path_training_dir)

from skimage import exposure


def crop_brain_contour(image, plot=False):

    # Convert the image to grayscale, and blur it slightly
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Apply Gaussian blur
    img = cv2.GaussianBlur(gray, (5, 5), 0)

    # Apply median filter
    img = cv2.medianBlur(img, 5)

    # Apply CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    img = clahe.apply(img)




    if plot:
        plt.figure()
        plt.subplot(1, 2, 1)
        plt.imshow(image)
        plt.tick_params(axis='both', which='both', top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)
        plt.title('Original Image')
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.tick_params(axis='both', which='both',top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)
        plt.title('Cropped Image')
        plt.show()

    return img

def crop_brain_contourr(image, plot=False):

    #import imutils
    #import cv2
    #from matplotlib import pyplot as plt

    # Convert the image to grayscale, and blur it slightly
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (5, 5), 0)
    gray = cv2.medianBlur(gray, 3)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    gray = clahe.apply(gray)
    # Threshold the image, then perform a series of erosions +
    # dilations to remove any small regions of noise
    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]
    thresh = cv2.erode(thresh, None, iterations=2)
    thresh = cv2.dilate(thresh, None, iterations=2)

    # Find contours in thresholded image, then grab the largest one
    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = imutils.grab_contours(cnts)
    c = max(cnts, key=cv2.contourArea)


    # Find the extreme points
    extLeft = tuple(c[c[:, :, 0].argmin()][0])
    extRight = tuple(c[c[:, :, 0].argmax()][0])
    extTop = tuple(c[c[:, :, 1].argmin()][0])
    extBot = tuple(c[c[:, :, 1].argmax()][0])

    # crop new image out of the original image using the four extreme points (left, right, top, bottom)
    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]

    if plot:
        plt.figure()

        plt.subplot(1, 2, 1)
        plt.imshow(image)

        plt.tick_params(axis='both', which='both',
                        top=False, bottom=False, left=False, right=False,
                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)

        plt.title('Original Image')

        plt.subplot(1, 2, 2)
        plt.imshow(new_image)

        plt.tick_params(axis='both', which='both',
                        top=False, bottom=False, left=False, right=False,
                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)

        plt.title('Cropped Image')

        plt.show()

    return new_image

from os import listdir, path
import cv2

def load_data(data_path, image_size):
    image_width, image_height = image_size
    X = []
    y = []
    labels = {}

    # Define a mapping of class names to numerical labels
    class_mapping = {'notumor': 0, 'pituitary': 1, 'glioma': 2, 'meningioma': 3}

    i = 0  # Counter for labels

    # Iterate over each subdirectory in the main directory
    for subdirectory in listdir(data_path):
        subdirectory_path = path.join(data_path, subdirectory)

        # Check if it's a directory
        if path.isdir(subdirectory_path):
            print(f"Processing subdirectory: {subdirectory}")

            # Assign numerical label based on the class mapping
            label = class_mapping.get(subdirectory, -1)
            if label != -1:
                # Iterate over each file in the subdirectory
                for filename in listdir(subdirectory_path):
                    # Set the label for the current image

                    labels[i] = label

                    # Read the image
                    #image = cv2.imread(path.join(subdirectory_path, filename),cv2.IMREAD_GRAYSCALE)
                    image = cv2.imread(path.join(subdirectory_path, filename))

                    # Crop the brain contour
                    image = crop_brain_contourr(image, plot=False)
                    # Resize the image
                    image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)
                    # Normalize values
                    image = image / 255.
                    #image = np.array(image)/255.0
                    # Convert image to numpy array and append it to X
                    X.append(image)
                    #X.append(image.reshape((image_width, image_height, 1)))
                    # Append the numerical label to the target array
                    y.append([label])

                    i += 1  # Increment label counter

    X = np.array(X)
    y = np.array(y)
 # Shuffle the data
    X, Y = shuffle(X, y)

    print(f'Number of examples is: {len(X)}')
    print(f'X shape is: {X.shape}')
    print(f'Y shape is: {Y.shape}')

    return X, Y, labels

"""The shuffle function ensures that the order of images and labels is randomized, which helps in avoiding any potential biases during model training. we are suffling x train and y train together to ensure that the images and their corresponding labels remain aligned after the randomization. we should choose randome state value as high as possible to ensure good number of suffling

In shape(3264, 150, 150, 3) The first element 3264, indicates that you have 3264 images in the training set. The second and third elements, 150 and 150, denote the height and width of each image, respectively. The last element, 3, represents the number of color channels in the image (assuming the images are RGB images; it would be 1 for grayscale images).
"""

# Example usage:
# Replace 'path_to_your_data_directory' with the actual path to your data directory
image_size = (64, 64)
X, y, labels = load_data(data_path_training_dir, image_size)

def split_data(X, y, test_size):

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state = 123,shuffle=True)
    #X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.2,random_state = 123)

    return X_train, y_train, X_test, y_test

X_train, y_train, X_test, y_test = split_data(X, y, test_size=0.25)

print ("number of training examples = " + str(X_train.shape[0]))
print ("number of test examples = " + str(X_test.shape[0]))

import keras
from keras.initializers import GlorotNormal
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Input, Rescaling,Activation,AveragePooling2D,GlobalAveragePooling2D
from keras.layers import Dropout, Flatten,Dense
import tensorflow as tf
from tensorflow.python.keras import regularizers


num_classes = 4



def build_model(input_shape):

    X_input = Input(input_shape)

    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding="same", activation="relu")(X_input)
    conv2 = Conv2D(filters=64, kernel_size=(3, 3), padding="same", activation="relu")(conv1)
    BN_2 = Conv2D(filters=64, kernel_size=(3, 3), padding="same", activation="relu")(conv2)


    vectorStart0_0 = Activation("relu")(BN_2)
    vectorStart0_0_avgp1=AveragePooling2D((2,2))(vectorStart0_0)

    vectorStart0_1=Conv2D(filters=64, kernel_size=(3, 3), padding="same", activation="relu")(BN_2)
    avgp1=AveragePooling2D((2,2))(vectorStart0_1)
    conv4=Conv2D(filters=64, kernel_size=(3, 3), padding="same", activation="relu")(avgp1)
    convv5=Conv2D(filters=64, kernel_size=(3, 3), padding="same", activation="relu")(conv4)

    add1 = tf.keras.layers.average([vectorStart0_0_avgp1, convv5])

    #------------------B2------------------
    conv5=Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu")(add1)


    vectorStart1_1=Activation("relu")(conv5)
    vectorStart0_0_avgp2=AveragePooling2D((2,2))(vectorStart1_1)

    vectorStart1_2=Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu")(conv5)
    avgp2=AveragePooling2D((2,2))(vectorStart1_2)
    conv6=Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu")(avgp2)
    conv6 = Dropout(rate=0.4)(conv6)

    conv6 = BatchNormalization()(conv6)

    avrg1=tf.keras.layers.average([vectorStart0_0_avgp2, conv6])

    # ---------------------B3-------------------

    conv7=Conv2D(filters=1024, kernel_size=(3, 3), padding="same", activation="relu")(avrg1)
    BN_4 = BatchNormalization()(conv7)

    vectorStart2_1_sideL=Activation("relu")(BN_4)
    vectorStart2_1_sideL_avgp1=AveragePooling2D((2,2))(vectorStart2_1_sideL)
    vectorStart2_1_sideL_avgp2=AveragePooling2D((2,2))(vectorStart2_1_sideL_avgp1)
    vectorStart2_1_sideL_avgp2 = BatchNormalization()(vectorStart2_1_sideL_avgp2)

    vectorStart2_2_0_0sideR=Conv2D(filters=1024, kernel_size=(3, 3), padding="same", activation="relu")(BN_4)

    vectorStart2_2_0_1sideR_L=Activation("relu")(vectorStart2_2_0_0sideR)
    vectorStart2_2_0_1sideR_L_avgp1=AveragePooling2D((2,2))(vectorStart2_2_0_1sideR_L)
    vectorStart2_2_0_1sideR_L_avgp2=AveragePooling2D((2,2))(vectorStart2_2_0_1sideR_L_avgp1)
    vectorStart2_2_0_1sideR_L_avgp2=Dropout(rate=0.6)(vectorStart2_2_0_1sideR_L_avgp2)

    vectorStart2_2_0_2sideR_R=Conv2D(filters=1024, kernel_size=(3, 3), padding="same", activation="relu",bias_regularizer=tf.keras.regularizers.L2(0.2))(vectorStart2_2_0_0sideR)
    avgp3=AveragePooling2D((2,2))(vectorStart2_2_0_2sideR_R)
    conv8=Conv2D(filters=1024, kernel_size=(3, 3), padding="same", activation="relu")(avgp3)
    conv9=Conv2D(filters=1024, kernel_size=(3, 3), padding="same", activation="relu")(conv8)
    avgp4=AveragePooling2D((2,2))(conv9)

    restAct = Activation("relu")(avgp4)

    multiplied1 = tf.keras.layers.average([vectorStart2_2_0_1sideR_L_avgp2, restAct])

    conv10=Conv2D(filters=1024, kernel_size=(3, 3), padding="same", activation="relu")(multiplied1)
    restAct1 = Activation("relu")(conv10)

    add2 = tf.keras.layers.add([vectorStart2_1_sideL_avgp2, restAct1])


 #----------------------------B4-------------------------

    conv11 = Conv2D(filters=1024, kernel_size=(3, 3), padding="same", activation="relu")(add2)
    avgp5=AveragePooling2D((4,4))(conv11)
    #BN_6 = BatchNormalization()(avgp5)



 #----------------------------B4-------------------------



    conv01 = Conv2D(filters=64, kernel_size=(2, 2), padding="same", activation="relu")(X_input)
    conv02 = Conv2D(filters=64, kernel_size=(2, 2), padding="same", activation="relu")(conv01)
    BN_01 = BatchNormalization()(conv02)
    avgp6_=AveragePooling2D((2,2))(BN_01)
    BN_02 = Conv2D(filters=64, kernel_size=(2, 2), padding="same", activation="relu")(avgp6_)
    avgp7_=AveragePooling2D((2,2))(BN_02)
    conv03 = Conv2D(filters=128, kernel_size=(2, 2), padding="same", activation="relu",bias_regularizer=tf.keras.regularizers.L2(0.0001))(avgp7_)
    BN_03 = BatchNormalization()(conv03)
    avgp8_=AveragePooling2D((2,2))(BN_03)
    BN_04 = Conv2D(filters=128, kernel_size=(2, 2), padding="same", activation="relu")(avgp8_)
    avgp9_=AveragePooling2D((2,2))(BN_04)
    conv04 = Conv2D(filters=512, kernel_size=(2, 2), padding="same", activation="relu")(avgp9_)
    conv06 = Conv2D(filters=1024, kernel_size=(2, 2), padding="same", activation="relu")(conv04)
    conv06=AveragePooling2D((2,2))(conv06)


    multiplied00 = tf.keras.layers.average([conv06, avgp5])

    #final_array = tf.keras.layers.Average()([pool, pool4_2])

    # ---------------------concatenation(whether, add or average)-------------------

    multiplied00=Dropout(rate=0.5)(multiplied00)
    flat = Flatten()(multiplied00)
    dense2 = Dense(1024, activation="relu")(flat)
    dense2=Dropout(rate=0.1)(dense2)
    dense3 = Dense(num_classes, activation="softmax",kernel_initializer=GlorotNormal(),kernel_regularizer= tf.keras.regularizers.L2(0.0001), bias_regularizer= tf.keras.regularizers.L2(0.0001))(dense2)
    model = Model(inputs = X_input, outputs = dense3)
    return model;

IMG_SHAPE = (64, 64,3)

model=build_model(IMG_SHAPE)

model.summary()

batch_sizes = 96
steps = int(len(X_train)/batch_sizes)
epochs = 30
print(steps)

#early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min',patience=6,restore_best_weights=True)
#Early stopping to avoid overfitting of model
#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,mode='auto',verbose=1)

from keras.utils import normalize

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint

tensorboard = TensorBoard(log_dir = 'logs')
checkpoint = ModelCheckpoint("/content/drive/MyDrive/braintumor_dataset/Tumor_detection_model.h5",monitor="val_accuracy",save_best_only=True,mode="auto",verbose=1)
reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,mode='auto',verbose=1)

learning_rate = 1e-4


#X_train = normalize(X_train, axis=1)
#X_test = normalize(X_test, axis=1)

model.compile(optimizer=tf.keras.optimizers.Lion(learning_rate),loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history= model.fit(x=X_train, y=y_train, batch_size=batch_sizes, epochs=epochs,verbose = 1, validation_data=(X_test, y_test),callbacks=[tensorboard,checkpoint,reduce_lr],steps_per_epoch=steps)
#history = model.fit(datagen.flow(X_train,y_train, batch_size = batch_sizes ) ,epochs = epochs, validation_data = datagen.flow(X_test, y_test) ,callbacks=[tensorboard,checkpoint,reduce_lr],steps_per_epoch=steps)

model.save('/content/drive/MyDrive/braintumor_dataset/Tumor_detection_model_.h5')
model.save('/content/drive/MyDrive/braintumor_dataset/Tumor_detection_model_.keras')

epochs = [i for i in range(30)]
fig , ax = plt.subplots(1,2)
train_acc = history.history['accuracy']
train_loss = history.history['loss']
val_acc = history.history['val_accuracy']
val_loss = history.history['val_loss']
fig.set_size_inches(20,10)

ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')
ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')
ax[0].set_title('Training & Validation Accuracy')
ax[0].legend()
ax[0].set_xlabel("Epochs")
ax[0].set_ylabel("Accuracy")

ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')
ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')
ax[1].set_title('Training & Validation Loss')
ax[1].legend()
ax[1].set_xlabel("Epochs")
ax[1].set_ylabel("Training & Validation Loss")
plt.show()

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from  keras.models import load_model
import tensorflow as tf
from sklearn.datasets import make_circles
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from keras.models import Sequential
from keras.layers import Dense

model = tf.keras.models.load_model('/content/drive/MyDrive/braintumor_dataset/97Tumor_detection_model01_11_10_20.h5')

data_path_testing_dir="/content/drive/MyDrive/braintumor_dataset/Testing"

image_size = (64, 64)
X1, y1, labels1 = load_data(data_path_testing_dir, image_size)

def split_data_fortesting(X, y, test_size):

    X_val1, X_test1, y_val1, y_test1 = train_test_split(X, y, test_size=test_size,random_state = 123)
    #X_val1, X_test1, y_val1, y_test1 = train_test_split(X, y, test_size=test_size,random_state = 123)

    return X_val1, y_val1, X_test1, y_test1

X_val1, y_val1, X_test1, y_test1 = split_data_fortesting(X1, y1, test_size=0.4)

print ("number of training examples = " + str(X_val1.shape[0]))
print ("number of test examples = " + str(X_test1.shape[0]))

from sklearn.metrics import accuracy_score

predictions = model.predict(X_test1)

# Convert the predictions to class labels
predicted_labels = np.argmax(predictions, axis=1)

true_labels = y_test1

# Compare predicted labels with true labels
accuracy = accuracy_score(true_labels, predicted_labels)
print(f"Accuracy: {accuracy:.3f}")

"""    ** class_mapping =  'notumor': 0, 'pituitary': 1, 'glioma': 2, 'meningioma': 3 **


"""

from sklearn.metrics import classification_report

print(classification_report(true_labels, predicted_labels))

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming y_true contains the true labels and y_pred contains the predicted labels

# Calculate the confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Plot the confusion matrix using seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3'], yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

from sklearn.datasets import make_circles
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from keras.models import Sequential
from keras.layers import Dense

# accuracy: (tp + tn) / (p + n)
accuracy = accuracy_score(true_labels, predicted_labels)
print('Accuracy: %f' % accuracy)
# precision tp / (tp + fp)
precision = precision_score(true_labels, predicted_labels, average='weighted')
print('Precision: %f' % precision)
# recall: tp / (tp + fn) or sensivity
recall = recall_score(true_labels, predicted_labels, average='weighted')
print('Recall: %f' % recall)
# f1: 2 tp / (2 tp + fp + fn)
f1 = f1_score(true_labels, predicted_labels, average='weighted')
print('F1 score: %f' % f1)

import matplotlib.pyplot as plt
import numpy as np

# Assuming you have:
# - `predictions`: Array of predicted class probabilities
# - `y_test1`: Array of true class labels (assume already converted to integers)
# - `X_test1`: Array of input images

# Set the grid dimensions for the 10x10 image layout
L = 10
W = 10

# Create the figure and axes
fig, axes = plt.subplots(L, W, figsize=(20, 20))  # Adjusted figsize for clearer images

# Reshape axes for efficient iteration and visualization
axes = axes.ravel()

# Function to determine label from probability
def get_label(pred):
    # Adjust thresholds and logic based on your model's output
    if pred < 0.6:
        return 0
    elif pred >= 0.6 and pred < 1.6 :
        return 1
    elif pred > 1.5 and pred <= 2.5:
        return 2
    else:
        return 3  # Adjust expected labels if needed

# Function to format prediction and label title
def format_title(pred, label):
    return f"Pred: {int(get_label(pred))}\nLabel: {label}"

# Iterate over each subplot and display image, prediction, and label
for i in np.arange(0, L * W):
  if i < len(X_test1):  # Check if index is within image range
    axes[i].imshow(X_test1[i])

    # Ensure `y_test1[i]` and `predicted_label` are integers before formatting
    axes[i].set_title(format_title(predicted_labels[i], true_labels[i]), fontsize=8)
    axes[i].axis('off')

# Adjust spacing between subplots for improved readability
plt.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95, wspace=0.1, hspace=0.2)

plt.show()